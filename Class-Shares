## Note: Please execute the following codes in Quantopian Notebook ... ##
## ... They would not work on local machine, since the pipeline and research libraries could not be downloaded. ##

## Import Python libraries ##
import datetime as dt
import pandas as pd
from quantopian.pipeline import Pipeline
from quantopian.pipeline.data.morningstar import Fundamentals
from quantopian.research import run_pipeline

## Construct factors that simply retrieve the most recent values ##
listed_exchange = Fundamentals.exchange_id.latest
share_type = Fundamentals.security_type.latest
share_class = Fundamentals.share_class_description.latest
share_class_status = Fundamentals.share_class_status.latest
share_symbol = Fundamentals.symbol.latest

## Add the factor to the pipeline ##
pipe = Pipeline(columns={'EXCHANGE': listed_exchange,
                         'SHARE_TYPE': share_type,
                         'SHARE_CLASS': share_class,
                         'SHARE_CLASS_STATUS': share_class_status,
                         'SHARE_SYMBOL': share_symbol})

## Run the pipeline for today and print the results ##
if int(dt.datetime.now().strftime('%H')) < 7:
    df = run_pipeline(pipe, 
                      (dt.datetime.now() + dt.timedelta(-1)).strftime('%Y-%m-%d'), 
                      (dt.datetime.now() + dt.timedelta(-1)).strftime('%Y-%m-%d'))
else:
    df = run_pipeline(pipe, 
                      dt.datetime.now().strftime('%Y-%m-%d'), 
                      dt.datetime.now().strftime('%Y-%m-%d'))
    
## Rearrange the order of the columns ##
df = df[['EXCHANGE', 'SHARE_SYMBOL', 'SHARE_TYPE', 'SHARE_CLASS', 'SHARE_CLASS_STATUS']]

## Initialize the variables ##
start = 0
end = 0

## Loop through the dataframe to print dataset ##
for i in range(len(df)):
    # Loop through the dataframe for every 50 rows and print partial dataset #
    if i > 0 and i % 50 == 0:
        end = i
        display(df[start:end])
        start = end
    # Loop through the dataframe for the remaining rows and print partial dataset #
    elif i == len(df)-1 and i % 50 != 0:
        display(df[start:i+1])

## The next step is to consider whether we should scrape the results ##

## Another way to scrape class shares information from Market Screener ##
## Import Python libraries ## 
from bs4 import BeautifulSoup
import datetime as dt
import Levenshtein as lev
import numpy as np
import os
import pandas as pd
import re
import requests
import xml.etree.ElementTree as ET
    
## Initialize variables ##
ms_url = 'https://www.marketscreener.com/search/instruments/equities/?aComposeInputSearch=s_'
filepath = 'C:\\Users\\C_YEE\\Projects\\data\\News' 

## Load Scientific Beta Stock Universe ##
SBSU_data = pd.read_excel(filepath + '\\SBSU.xlsx')
SBSU_ticker_list = list(SBSU_data['BBG_STOCK_TICKER']) 

## GET request ##
for ticker in SBSU_ticker_list[1332:1333]:
    # Assign ticker's country to 'country' variable #
    country = SBSU_data.loc[SBSU_data['BBG_STOCK_TICKER']==ticker,['country']]['country'].iloc[0]
    # Send GET request for each ticker #
    r = requests.get(ms_url + str(ticker))
    # Parse the html details collected from GET request #
    first_soup = BeautifulSoup(r.text, 'html.parser')
    # Find the first table that matches the specific class parameters #
    table = first_soup.find_all('table', {'class': 'tabBodyLV17'})[0]
    # Get all row details from the first table #
    rows = table.find_all('tr')[1:]
    for row in rows:
        data = row.find('td').find_next_siblings()
        if country in data[0].img['title']:
            url = 'https://www.marketscreener.com' + str(data[1].a['href']) + 'company/'
            r = requests.get(url)
            second_soup = BeautifulSoup(r.text, 'html.parser')
            tables = second_soup.find_all('table', {'class': 'nfvtTab'})
            for table in tables:
                if table.find_all('td', {'title': 'Voting rights per share'}):
                    rows = table.find_all('tr')[1:]
